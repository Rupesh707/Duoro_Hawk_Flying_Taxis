{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import datetime, gc, random\n",
    "import json, numpy as np, pandas as pd, zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "import datetime\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# parameter opimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Validation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/data/train_df.csv\")\n",
    "test_df = pd.read_csv(\"/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/data/test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>WEATHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>1372636858</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20000596</td>\n",
       "      <td>1372637303</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "      <td>Foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1372636951620000320</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000320</td>\n",
       "      <td>1372636951</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.612964,41.140359],[-8.613378,41.14035],[-...</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1372636854</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.574678,41.151951],[-8.574705,41.151942],[...</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>1372637091</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "      <td>Windy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710665</th>\n",
       "      <td>1710665</td>\n",
       "      <td>1404171463620000698</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000698</td>\n",
       "      <td>1404171463</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.612469,41.14602],[-8.612487,41.145993],[-...</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710666</th>\n",
       "      <td>1710666</td>\n",
       "      <td>1404171367620000670</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000670</td>\n",
       "      <td>1404171367</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610138,41.140845],[-8.610174,41.140935],[...</td>\n",
       "      <td>Windy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710667</th>\n",
       "      <td>1710667</td>\n",
       "      <td>1388745716620000264</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000264</td>\n",
       "      <td>1388745716</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Windy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710668</th>\n",
       "      <td>1710668</td>\n",
       "      <td>1404141826620000248</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20000248</td>\n",
       "      <td>1404141826</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.630712,41.154885],[-8.63073,41.154813],[-...</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710669</th>\n",
       "      <td>1710669</td>\n",
       "      <td>1404157147620000079</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20000079</td>\n",
       "      <td>1404157147</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.615538,41.140629],[-8.615421,41.140746],[...</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710670 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0              TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "0                 0  1372636858620000589         C          NaN           NaN   \n",
       "1                 1  1372637303620000596         B          NaN           7.0   \n",
       "2                 2  1372636951620000320         C          NaN           NaN   \n",
       "3                 3  1372636854620000520         C          NaN           NaN   \n",
       "4                 4  1372637091620000337         C          NaN           NaN   \n",
       "...             ...                  ...       ...          ...           ...   \n",
       "1710665     1710665  1404171463620000698         C          NaN           NaN   \n",
       "1710666     1710666  1404171367620000670         C          NaN           NaN   \n",
       "1710667     1710667  1388745716620000264         C          NaN           NaN   \n",
       "1710668     1710668  1404141826620000248         B          NaN          12.0   \n",
       "1710669     1710669  1404157147620000079         B          NaN          34.0   \n",
       "\n",
       "          TAXI_ID   TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "0        20000589  1372636858        A         False   \n",
       "1        20000596  1372637303        A         False   \n",
       "2        20000320  1372636951        A         False   \n",
       "3        20000520  1372636854        A         False   \n",
       "4        20000337  1372637091        A         False   \n",
       "...           ...         ...      ...           ...   \n",
       "1710665  20000698  1404171463        A         False   \n",
       "1710666  20000670  1404171367        A         False   \n",
       "1710667  20000264  1388745716        A         False   \n",
       "1710668  20000248  1404141826        A         False   \n",
       "1710669  20000079  1404157147        A         False   \n",
       "\n",
       "                                                  POLYLINE WEATHER  \n",
       "0        [[-8.618643,41.141412],[-8.618499,41.141376],[...   Rainy  \n",
       "1        [[-8.639847,41.159826],[-8.640351,41.159871],[...   Foggy  \n",
       "2        [[-8.612964,41.140359],[-8.613378,41.14035],[-...   Rainy  \n",
       "3        [[-8.574678,41.151951],[-8.574705,41.151942],[...  Cloudy  \n",
       "4        [[-8.645994,41.18049],[-8.645949,41.180517],[-...   Windy  \n",
       "...                                                    ...     ...  \n",
       "1710665  [[-8.612469,41.14602],[-8.612487,41.145993],[-...  Cloudy  \n",
       "1710666  [[-8.610138,41.140845],[-8.610174,41.140935],[...   Windy  \n",
       "1710667                                                 []   Windy  \n",
       "1710668  [[-8.630712,41.154885],[-8.63073,41.154813],[-...   Sunny  \n",
       "1710669  [[-8.615538,41.140629],[-8.615421,41.140746],[...   Sunny  \n",
       "\n",
       "[1710670 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>WEATHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000542</td>\n",
       "      <td>1408039037</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.585676,41.148522],[-8.585712,41.148639],[...</td>\n",
       "      <td>Foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000108</td>\n",
       "      <td>1408038611</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610876,41.14557],[-8.610858,41.145579],[-...</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000370</td>\n",
       "      <td>1408038568</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.585739,41.148558],[-8.58573,41.148828],[-...</td>\n",
       "      <td>Foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000492</td>\n",
       "      <td>1408039090</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.613963,41.141169],[-8.614125,41.141124],[...</td>\n",
       "      <td>Foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20000621</td>\n",
       "      <td>1408039177</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.619903,41.148036],[-8.619894,41.148036]]</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>A</td>\n",
       "      <td>70885.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000430</td>\n",
       "      <td>1419171485</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.570196,41.159484],[-8.570187,41.158962],[...</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000020</td>\n",
       "      <td>1419170802</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.613873,41.141232],[-8.613882,41.141241],[...</td>\n",
       "      <td>Foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000207</td>\n",
       "      <td>1419172121</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.6481,41.152536],[-8.647461,41.15241],[-8....</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>A</td>\n",
       "      <td>76232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000667</td>\n",
       "      <td>1419171980</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.571699,41.156073],[-8.570583,41.155929],[...</td>\n",
       "      <td>Windy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>A</td>\n",
       "      <td>31208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000255</td>\n",
       "      <td>1419171420</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.574561,41.180184],[-8.572248,41.17995],[-...</td>\n",
       "      <td>Windy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP  \\\n",
       "0        T1         B          NaN          15.0  20000542  1408039037   \n",
       "1        T2         B          NaN          57.0  20000108  1408038611   \n",
       "2        T3         B          NaN          15.0  20000370  1408038568   \n",
       "3        T4         B          NaN          53.0  20000492  1408039090   \n",
       "4        T5         B          NaN          18.0  20000621  1408039177   \n",
       "..      ...       ...          ...           ...       ...         ...   \n",
       "315    T323         A      70885.0           NaN  20000430  1419171485   \n",
       "316    T324         B          NaN          53.0  20000020  1419170802   \n",
       "317    T325         C          NaN           NaN  20000207  1419172121   \n",
       "318    T326         A      76232.0           NaN  20000667  1419171980   \n",
       "319    T327         A      31208.0           NaN  20000255  1419171420   \n",
       "\n",
       "    DAY_TYPE  MISSING_DATA                                           POLYLINE  \\\n",
       "0          A         False  [[-8.585676,41.148522],[-8.585712,41.148639],[...   \n",
       "1          A         False  [[-8.610876,41.14557],[-8.610858,41.145579],[-...   \n",
       "2          A         False  [[-8.585739,41.148558],[-8.58573,41.148828],[-...   \n",
       "3          A         False  [[-8.613963,41.141169],[-8.614125,41.141124],[...   \n",
       "4          A         False      [[-8.619903,41.148036],[-8.619894,41.148036]]   \n",
       "..       ...           ...                                                ...   \n",
       "315        A         False  [[-8.570196,41.159484],[-8.570187,41.158962],[...   \n",
       "316        A         False  [[-8.613873,41.141232],[-8.613882,41.141241],[...   \n",
       "317        A         False  [[-8.6481,41.152536],[-8.647461,41.15241],[-8....   \n",
       "318        A         False  [[-8.571699,41.156073],[-8.570583,41.155929],[...   \n",
       "319        A         False  [[-8.574561,41.180184],[-8.572248,41.17995],[-...   \n",
       "\n",
       "    WEATHER  \n",
       "0     Foggy  \n",
       "1    Cloudy  \n",
       "2     Foggy  \n",
       "3     Foggy  \n",
       "4     Rainy  \n",
       "..      ...  \n",
       "315   Sunny  \n",
       "316   Foggy  \n",
       "317  Cloudy  \n",
       "318   Windy  \n",
       "319   Windy  \n",
       "\n",
       "[320 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1710670 entries, 0 to 1710669\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Unnamed: 0    int64  \n",
      " 1   TRIP_ID       int64  \n",
      " 2   CALL_TYPE     object \n",
      " 3   ORIGIN_CALL   float64\n",
      " 4   ORIGIN_STAND  float64\n",
      " 5   TAXI_ID       int64  \n",
      " 6   TIMESTAMP     int64  \n",
      " 7   DAY_TYPE      object \n",
      " 8   MISSING_DATA  bool   \n",
      " 9   POLYLINE      object \n",
      " 10  WEATHER       object \n",
      "dtypes: bool(1), float64(2), int64(4), object(4)\n",
      "memory usage: 132.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "TRIP_ID               0\n",
       "CALL_TYPE             0\n",
       "ORIGIN_CALL     1345900\n",
       "ORIGIN_STAND     904091\n",
       "TAXI_ID               0\n",
       "TIMESTAMP             0\n",
       "DAY_TYPE              0\n",
       "MISSING_DATA          0\n",
       "POLYLINE              0\n",
       "WEATHER               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique values for features Unnamed: 0 : 1710670\n",
      "The number of unique values for features TRIP_ID : 1710589\n",
      "The number of unique values for features CALL_TYPE : 3 --- ['A' 'B' 'C']\n",
      "The number of unique values for features ORIGIN_CALL : 57106\n",
      "The number of unique values for features ORIGIN_STAND : 64\n",
      "The number of unique values for features TAXI_ID : 448\n",
      "The number of unique values for features TIMESTAMP : 1655366\n",
      "The number of unique values for features DAY_TYPE : 1 --- ['A']\n",
      "The number of unique values for features MISSING_DATA : 2 --- [False  True]\n",
      "The number of unique values for features POLYLINE : 1703650\n",
      "The number of unique values for features WEATHER : 5 --- ['Cloudy' 'Foggy' 'Rainy' 'Sunny' 'Windy']\n"
     ]
    }
   ],
   "source": [
    "for colum in train_df:\n",
    "    unique_values = np.unique(train_df[colum])\n",
    "    nr_values = len(unique_values)\n",
    "    if nr_values < 22:\n",
    "        print(\"The number of unique values for features {} : {} --- {}\".format(colum, nr_values,unique_values))\n",
    "    else:\n",
    "         print(\"The number of unique values for features {} : {}\".format(colum, nr_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time data preprocessing\n",
    "train_df[\"TIMESTAMP\"] = [float(time) for time in train_df[\"TIMESTAMP\"]]\n",
    "train_df[\"data_time\"] = [datetime.datetime.fromtimestamp(time, datetime.timezone.utc) for time in train_df[\"TIMESTAMP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"data_time\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"year\"] = train_df[\"data_time\"].dt.year\n",
    "train_df[\"month\"] = train_df[\"data_time\"].dt.month\n",
    "train_df[\"day\"] = train_df[\"data_time\"].dt.day\n",
    "train_df[\"hour\"] = train_df[\"data_time\"].dt.hour\n",
    "train_df[\"min\"] = train_df[\"data_time\"].dt.minute\n",
    "train_df[\"weekday\"] = train_df[\"data_time\"].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(train_df, x='CALL_TYPE', color='CALL_TYPE')\n",
    "fig.update_layout(\n",
    "    title_text='Call Type Distribution', # title of plot\n",
    "    xaxis_title_text='Call Type', # xaxis label\n",
    "    yaxis_title_text='Count', # yaxis label\n",
    "    bargap=0.2), # gap between bars of adjacent location coordinates\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from fastai.imports import *\n",
    "import torch.nn as nn\n",
    "from fastai.learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_df.POLYLINE[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(test_df.POLYLINE[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train_df.copy()\n",
    "test2 = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "for l in test_df.TAXI_ID.unique():\n",
    "    if l not in train_df.TAXI_ID.unique():\n",
    "        s = s+1\n",
    "p=0\n",
    "g = []\n",
    "for l in test_df.ORIGIN_CALL.unique():\n",
    "    if l not in train_df.ORIGIN_CALL.unique():\n",
    "        p = p+1\n",
    "        g.append(l)\n",
    "s,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_mean = 41.15731\n",
    "lat_std = 0.074120656\n",
    "long_mean = -8.6161413\n",
    "long_std = 0.057200309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_stop_inputs(k, train, test):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function used to take first k and last k coordinates from given polyline.\n",
    "    For train - if total coordinates < 2 then return none, if > 2*k then return first k and last k\n",
    "    and if > 2 but < 2*k then do edge padding and return.\n",
    "    \n",
    "    \"\"\"\n",
    "    result_train = []\n",
    "    result_test = []\n",
    "    \n",
    "    for l in train[['LONGITUDE','LATITUDE']].iterrows():\n",
    "        if len(l[1][0]) < 2 or len(l[1][1]) < 2:\n",
    "            result_train.append(np.nan)\n",
    "        elif len(l[1][0][:-1]) >= 2*k:\n",
    "            result_train.append(np.concatenate([l[1][0][0:k],l[1][0][-k:],\n",
    "                                          l[1][1][0:k],l[1][1][-k:]]).flatten())\n",
    "        else:\n",
    "            l1 = np.lib.pad(l[1][0][:-1], (0,4*k-len(l[1][0][:-1])), mode='edge')\n",
    "            l2 = np.lib.pad(l[1][1][:-1], (0,4*k-len(l[1][1][:-1])), mode='edge')\n",
    "            result_train.append(np.concatenate([l1[0:k],l1[-k:],l2[0:k],l2[-k:]]).flatten())\n",
    "\n",
    "    for l in test[['LONGITUDE','LATITUDE']].iterrows(): \n",
    "        if len(l[1][0]) < 1 or len(l[1][1]) < 1:\n",
    "            result_test.append(np.nan)\n",
    "        elif len(l[1][0]) >= 2*k:\n",
    "            result_test.append(np.concatenate([l[1][0][0:k],l[1][0][-k:],l[1][1][0:k],l[1][1][-k:]]).flatten())\n",
    "        else:\n",
    "            l1 = np.lib.pad(l[1][0], (0,4*k-len(l[1][0])), mode='edge')\n",
    "            l2 = np.lib.pad(l[1][1], (0,4*k-len(l[1][1])), mode='edge')\n",
    "            result_test.append(np.concatenate([l1[0:k],l1[-k:],l2[0:k],l2[-k:]]).flatten())\n",
    "    \n",
    "    return pd.Series(result_train), pd.Series(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def feature_ext(train, test):   \n",
    "    \"\"\"\n",
    "    Function used to extract model features.\n",
    "    â€¢ extract lat/long from polyline\n",
    "    â€¢ lat/long normalized using pre-calculated mean and std\n",
    "    â€¢ origin_call and taxi_id converted to continuous numbers to get embeddings later\n",
    "    â€¢ categories convert to cat codes\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # origin_call -- train\n",
    "    train.ORIGIN_CALL.fillna(value = -1, inplace=True)\n",
    "    id_uniq = train.ORIGIN_CALL.unique()\n",
    "    \n",
    "    origin_call_dict = {o:i for i,o in enumerate(id_uniq)}\n",
    "\n",
    "    train['ORIGIN_CALL'] = train.ORIGIN_CALL.apply(lambda x: 0 if x == -1 \n",
    "                                                   or x == '' else origin_call_dict[x])\n",
    "    \n",
    "    \n",
    "    # origin_call --test (g list of ids in test not in train)\n",
    "    test.ORIGIN_CALL.fillna(value = -1, inplace=True)\n",
    "\n",
    "    test['ORIGIN_CALL'] = test.ORIGIN_CALL.apply(lambda x: 0 if x == -1 or x == '' \n",
    "                                              else (-2 if x in g[1:] else origin_call_dict[x]))\n",
    "    \n",
    "    \n",
    "    # origin_stand\n",
    "    train['ORIGIN_STAND']= pd.Series([0 if pd.isnull(x) or x=='' else int(x) for x in train[\"ORIGIN_STAND\"]])\n",
    "    test['ORIGIN_STAND']= pd.Series([0 if pd.isnull(x) or x=='' else int(x) for x in test[\"ORIGIN_STAND\"]])\n",
    "    \n",
    "    # taxi_id\n",
    "    id_uniq = train.TAXI_ID.unique()\n",
    "    taxi_id_dict = {o:i for i,o in enumerate(id_uniq)}\n",
    "    train['TAXI_ID'] = train.TAXI_ID.apply(lambda x: taxi_id_dict[x])\n",
    "    test['TAXI_ID'] = test.TAXI_ID.apply(lambda x: taxi_id_dict[x])\n",
    "\n",
    "    # day_type and call_type\n",
    "    # want 0 for A, 1 for B and 2 for C\n",
    "    train['DAY_TYPE'] = pd.Series([ord(x[0]) - ord('A') for x in train['DAY_TYPE']])\n",
    "    train['CALL_TYPE'] = pd.Series([ord(x[0]) - ord('A') for x in train['CALL_TYPE']])\n",
    "    test['DAY_TYPE'] = pd.Series([ord(x[0]) - ord('A') for x in test['DAY_TYPE']])\n",
    "    test['CALL_TYPE'] = pd.Series([ord(x[0]) - ord('A') for x in test['CALL_TYPE']])\n",
    "    \n",
    "    \n",
    "    # polyline\n",
    "    polyline1 = pd.Series([ast.literal_eval(x) for x in train['POLYLINE']])\n",
    "    polyline2 = pd.Series([ast.literal_eval(x) for x in test['POLYLINE']])\n",
    "    \n",
    "    # latitude and longitude\n",
    "    train['LATITUDE'] = pd.Series([np.array([point[1] for point in poly],dtype=np.float32) for poly in polyline1])\n",
    "    train['LONGITUDE'] = pd.Series([np.array([point[0] for point in poly],dtype=np.float32) for poly in polyline1])\n",
    "    \n",
    "    test['LATITUDE'] = pd.Series([np.array([point[1] for point in poly],dtype=np.float32) for poly in polyline2])\n",
    "    test['LONGITUDE'] = pd.Series([np.array([point[0] for point in poly],dtype=np.float32) for poly in polyline2])\n",
    "    \n",
    "    # target variable i.e. last coordinates\n",
    "    train['TARGET'] = pd.Series([[l[1][0][-1], l[1][1][-1]] if len(l[1][0]) > 1 \n",
    "                                else np.nan for l in train[['LONGITUDE','LATITUDE']].iterrows()])\n",
    "\n",
    "    # normalized lat long. We need normalized data for neural nets and this is like cont. variable (not cat)\n",
    "    train['LATITUDE'] = pd.Series([(t-lat_mean)/lat_std for t in train['LATITUDE']])\n",
    "    test['LATITUDE'] = pd.Series([(t-lat_mean)/lat_std for t in test['LATITUDE']])\n",
    "    \n",
    "    train['LONGITUDE'] = pd.Series([(t-long_mean)/long_std for t in train['LONGITUDE']])\n",
    "    test['LONGITUDE'] = pd.Series([(t-long_mean)/long_std for t in test['LONGITUDE']])\n",
    "\n",
    "    # first 5 and last 5 features\n",
    "    train['COORD_FEATURES'], test['COORD_FEATURES'] = start_stop_inputs(5, train, test)\n",
    "\n",
    "        \n",
    "    #data = data.dropna()\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, test2 = train_df.copy(), test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, test2 = feature_ext(train2, test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_1st_lon = []\n",
    "for i in range(0,len(train_df[\"POLYLINE\"])):\n",
    "    if train_df[\"POLYLINE\"][i] == '[]':\n",
    "        k=0\n",
    "        lists_1st_lon.append(k)\n",
    "    else:\n",
    "        k = re.sub(r\"[[|[|]|]|]]\", \"\", train_df[\"POLYLINE\"][i]).split(\",\")[0]\n",
    "        lists_1st_lon.append(k)\n",
    "        \n",
    "train_df[\"lon_1st\"] = lists_1st_lon\n",
    "\n",
    "# First latitude\n",
    "lists_1st_lat = []\n",
    "for i in range(0,len(train_df[\"POLYLINE\"])):\n",
    "    if train_df[\"POLYLINE\"][i] == '[]':\n",
    "        k=0\n",
    "        lists_1st_lat.append(k)\n",
    "    else:\n",
    "        k = re.sub(r\"[[|[|]|]|]]\", \"\", train_df[\"POLYLINE\"][i]).split(\",\")[1]\n",
    "        lists_1st_lat.append(k)\n",
    "        \n",
    "train_df[\"lat_1st\"] = lists_1st_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last longitude\n",
    "lists_last_lon = []\n",
    "for i in range(0,len(train_df[\"POLYLINE\"])):\n",
    "        if train_df[\"POLYLINE\"][i] == '[]':\n",
    "            k=0\n",
    "            lists_last_lon.append(k)\n",
    "        else:\n",
    "            k = re.sub(r\"[[|[|]|]|]]\", \"\", train_df[\"POLYLINE\"][i]).split(\",\")[-2]\n",
    "            lists_last_lon.append(k)\n",
    "\n",
    "train_df[\"lon_last\"] = lists_last_lon\n",
    "\n",
    "# Last latitude\n",
    "lists_last_lat = []\n",
    "for i in range(0,len(train_df[\"POLYLINE\"])):\n",
    "    if train_df[\"POLYLINE\"][i] == '[]':\n",
    "        k=0\n",
    "        lists_last_lat.append(k)\n",
    "    else:\n",
    "        k = re.sub(r\"[[|[|]|]|]]\", \"\", train_df[\"POLYLINE\"][i]).split(\",\")[-1]\n",
    "        lists_last_lat.append(k)\n",
    "        \n",
    "train_df[\"lat_last\"] = lists_last_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.query(\"lon_last != 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"lon_1st\"] = [float(k) for k in train_df[\"lon_1st\"]]\n",
    "train_df[\"lat_1st\"] = [float(k) for k in train_df[\"lat_1st\"]]\n",
    "train_df[\"lon_last\"] = [float(k) for k in train_df[\"lon_last\"]]\n",
    "train_df[\"lat_last\"] = [float(k) for k in train_df[\"lat_last\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Dec  7 2022, 10:15:13) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
