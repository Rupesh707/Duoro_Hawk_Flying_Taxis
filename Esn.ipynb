{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "from matplotlib.pyplot import*\n",
    "import calendar\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Esn:\n",
    "    def __init__(self, Nu=1, Ny=1, Nr=100, a=1, conn=100, rho=0.99, Lambda=0, win=1, lsv=True):\n",
    "        \"\"\"\n",
    "         Constructor of the net, prepare and initialize the esn\n",
    "        :param Nu: input units\n",
    "        :param Ny: output units\n",
    "        :param Nr: reservoir size\n",
    "        :param a: leaking rake\n",
    "        :param conn: % of connectivity\n",
    "        :param rho: or lsv to which scale the reservoir\n",
    "        :param Lambda: regularization parameter\n",
    "        :param win: input weights scaling\n",
    "        :param lsv: True - use the largest sing value for normalizing W\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.Nu = Nu  # input dim\n",
    "        self.Ny = Ny  # output dim\n",
    "        self.Nr = Nr  # reservoir dim\n",
    "        self.a = a  # leaking rate\n",
    "        self.connectivity = conn\n",
    "        self.Lambda = Lambda  # regularization coefficient\n",
    "        self.x = np.zeros((self.Nr, 1))  # init the reservoir-net-state\n",
    "\n",
    "        np.random.seed(5)  # fixed\n",
    "        # input connections, plus the bias unit\n",
    "        self.W_in = (np.random.rand(Nr, 1 + Nu) - 0.5) * win  # win is the input scaling\n",
    "        # reservoir connections, make them sparse!\n",
    "        self.W = np.random.rand(Nr, Nr) - 0.5\n",
    "        # -5 halves the values\n",
    "        eps = 0.5 * conn / 100\n",
    "        # leave only the conn % of the connections\n",
    "        self.W[abs(self.W) > eps] = 0\n",
    "        self.W_out = np.zeros((Nr, Nr))\n",
    "\n",
    "        if not lsv:\n",
    "            print ('Computing spectral radius...'),\n",
    "            t1 = datetime.now()\n",
    "            rhoW = np.max(np.abs(linalg.eigvals(self.W)))  # esn necessary condition\n",
    "            self.W *= rho / rhoW\n",
    "\n",
    "        else:\n",
    "            print ('Computing largest sing value...'),\n",
    "            t1 = datetime.now()\n",
    "            # compute the matrix 2-norm (largest sing. value), esn sufficient condition\n",
    "            lsv = linalg.norm(self.W, 2)\n",
    "            self.W *= rho / lsv\n",
    "\n",
    "        t2 = datetime.now()\n",
    "        print ('done in '),\n",
    "        print (t2 - t1).total_seconds(),\n",
    "        print (\"sec\")\n",
    "\n",
    "    def fit_data(self, data, washoutLen=0):\n",
    "        \"\"\"\n",
    "         the reservoir-net-state is updated for each training sample,\n",
    "         warm-up with washoutLen rows\n",
    "        :param data: the sequence: a matrix with a pattern per row\n",
    "        :param washoutLen: transient to discard\n",
    "        :return: the collected activation state\n",
    "        \"\"\"\n",
    "        # allocated memory for the design (collected states) matrix\n",
    "        # X instead of  [1|U|X]\n",
    "        X = np.zeros((1 + self.Nu + self.Nr, data.shape[0] - washoutLen))\n",
    "        # XX = np.zeros((1 + Nu + Nr, 1 + Nu + Nr))\n",
    "        # YX = np.zeros((Ny, 1 + Nu + Nr))\n",
    "        # run the reservoir with the data and collect X, skip washoutLen elements \"wash out\"\n",
    "        self.x = np.zeros(self.Nr)  # start from the 0 state\n",
    "        for t in range(washoutLen):\n",
    "            u = data[t]\n",
    "            u = np.append(1, u)\n",
    "            self.x = (1 - self.a) * self.x \\\n",
    "                     + self.a * np.tanh(np.dot(self.W_in, u) + np.dot(self.W, self.x))\n",
    "\n",
    "        for t in range(washoutLen, data.shape[0]):\n",
    "            u = data[t]\n",
    "            u = np.append(1, u)\n",
    "            self.x = (1 - self.a) * self.x \\\n",
    "                     + self.a * np.tanh(np.dot(self.W_in, u) + np.dot(self.W, self.x))\n",
    "            # the states matrix X stores also the input u, for direct input-output connections\n",
    "            X[:, t - washoutLen] = np.append(u, self.x)\n",
    "            # x1 = np.vstack((1, u, x))\n",
    "            # XX += np.dot(x1, x1.T)  # cumulative update of the design matrix\n",
    "            # YX += np.dot(u, x1.T)  # cumulative update\n",
    "        return X\n",
    "\n",
    "    def train_wout(self, X, Yt, Lambda):\n",
    "        \"\"\"\n",
    "         train the output Wout, given X and the relative Yt\n",
    "        :param X: collected (col-wise) training states, [x(1),x(2),..]\n",
    "        :param Yt: collected (col-wise) target outputs, [y1,y2,..]\n",
    "        :param Lambda: regularization param\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # also input and bias units contribute for the output\n",
    "        # X instead of  [1|U|X]\n",
    "        X_T = X.T\n",
    "        YX = np.dot(Yt, X_T)\n",
    "        self.W_out = np.dot(YX, linalg.inv(np.dot(X, X_T) + Lambda * np.eye(1 + self.Nu + self.Nr)))\n",
    "        # W_out = dot( Yt, linalg.pinv(X) )\n",
    "        # W_out = np.dot(YX, linalg.inv(XX + Lambda * np.eye(1 + Nu + Nr)))  # using the precomputed XX & YX\n",
    "\n",
    "    def predict(self, data_test, x, washoutLen=0, generative_mode=True):\n",
    "        \"\"\"\n",
    "         the test method does not modify the reservoir-net-state\n",
    "         it uses all the data skipping the first washoutLen rows\n",
    "        :param data_test: sequence, matrix with a sample per row, as many cols as sample-attributes\n",
    "        :param x: is the starting state of the reservoir\n",
    "        :param washoutLen: num of patterns just to warm up the state\n",
    "        :param generative_mode: True, the output is used as the next input (self-feeding);\n",
    "                                False, takes the input from the data\n",
    "        :return: a matrix with one predicted output per row one foreach test pattern\n",
    "        \"\"\"\n",
    "        # preallocate the output matrix\n",
    "        Y = np.zeros((data_test.shape[0] - washoutLen, self.Ny))\n",
    "\n",
    "        for t in range(washoutLen):\n",
    "            u = data_test[t]\n",
    "            u = np.append(1, u)\n",
    "            # just \"warm up\" the net state x\n",
    "            x = (1 - self.a) * x + self.a * np.tanh(\n",
    "                np.dot(self.W_in, u) + np.dot(self.W, x))\n",
    "\n",
    "        length = data_test.shape[0] - 1\n",
    "        # start testing with the left sequence\n",
    "        u = data_test[washoutLen]\n",
    "        for t in range(washoutLen, data_test.shape[0]):\n",
    "            u = np.append(1, u)\n",
    "            x = (1 - self.a) * x \\\n",
    "                + self.a * np.tanh(np.dot(self.W_in, u) + np.dot(self.W, x))\n",
    "\n",
    "            y = np.dot(self.W_out, np.append(u, x))\n",
    "            Y[t - washoutLen] = y  # insert the output y row-wise\n",
    "            if generative_mode:\n",
    "                # generative mode, feed the output to the next input:\n",
    "                u = y\n",
    "            else:\n",
    "                # predictive mode, take the next input from the data:\n",
    "                if t < length:\n",
    "                    u = data_test[t + 1]  # the new input is taken from the test set\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ntrips_train, ntrips_test, washout_fraction=0):\n",
    "    \"\"\"\n",
    "      data loading and preprocessing\n",
    "    :param ntrips_train:\n",
    "    :param ntrips_test:\n",
    "    :param washout_fraction:\n",
    "    :return: the tuple data_train, data_test, Tcollected, (minlon, maxlon, minlat, maxlat)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    note: for the charts the (lat, long) coordinates correspond to (y, x) in the cartesian plane\n",
    "    in the polyline they are memorized as (long, lat) gps points\n",
    "    \"\"\"\n",
    "    print (\"loading data...\"),\n",
    "    data_train = pd.read_csv('datasets/train.csv', nrows=ntrips_train,\n",
    "                             usecols=[\"TRIP_ID\", \"POLYLINE\"],\n",
    "                             converters={\n",
    "                                 'POLYLINE': lambda x: np.array(json.loads(x))})  # [[lon lat]...[lon lat]] layout\n",
    "    print (\"done\")\n",
    "\n",
    "    data_train['triplen'] = data_train[\"POLYLINE\"].apply(lambda x: x.shape[0])\n",
    "    data_train = data_train[data_train['triplen'] > 0]\n",
    "\n",
    "    # create the training trips image\n",
    "    plot_trips(data_train, ntrips_train, \"taxi_train_trips.png\")\n",
    "    printLenStats(data_train)\n",
    "\n",
    "    # normalize the trajectories\n",
    "    minlat, maxlat, minlon, maxlon = computeNormParams(data_train)\n",
    "    data_train.POLYLINE.apply(lambda x: minmaxnorm2d(x, minlon, maxlon, minlat, maxlat))\n",
    "\n",
    "    # build the training target set\n",
    "    data_train['target'] = 's'\n",
    "    for idx, row in data_train.iterrows():\n",
    "        l = row[\"triplen\"]\n",
    "        # v is a tuple (targetlon, targetlat)\n",
    "        v = row[\"POLYLINE\"][-1]\n",
    "        # replicate it for the length of each trip, discarding transient% of the trip\n",
    "        v = [(v[0], v[1])] * (l - int(l * washout_fraction))\n",
    "        data_train.set_value(idx, 'target', v)\n",
    "    # cumulate the target [t1t1t1,..,tntntntn] and transpose for col-wise collection\n",
    "    Tcollected = np.array([y for x in data_train['target'] for y in x]).T\n",
    "    data_train.drop(['target', 'triplen'], axis=1, inplace=True)\n",
    "\n",
    "    # loading validation test data\n",
    "    print (\"loading test data...\"),\n",
    "    data_test = pd.read_csv('/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/data/train_df.csv',\n",
    "                            nrows=ntrips_test, skiprows=range(1, ntrips_train),\n",
    "                            usecols=[\"trip_ID\", 'POLYLINE'],\n",
    "                            converters={'POLYLINE': lambda x: np.array(json.loads(x))})  # [[long lat]...[]]\n",
    "    print (\"done\")\n",
    "\n",
    "    # data_test = data_test.sample(1000)\n",
    "    l = data_test[\"POLYLINE\"].apply(lambda x: x.shape[0])\n",
    "    data_test = data_test[l > 0]\n",
    "\n",
    "    # create the test trips image\n",
    "    plot_trips(data_train, ntrips_train, \"taxi_test_trips.png\")\n",
    "\n",
    "    # normalize the trips points wrt the training data\n",
    "    data_test.POLYLINE.apply(lambda x: minmaxnorm2d(x, minlon, maxlon, minlat, maxlat))\n",
    "\n",
    "    return data_train, data_test, Tcollected, (minlon, maxlon, minlat, maxlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data Mackey\n",
    "train_rows = 2000\n",
    "test_rows = 500\n",
    "# els just to init the reservoir state x\n",
    "trainWashout = 100\n",
    "testWashout = 0\n",
    "\n",
    "print (\"loading data...\"),\n",
    "v = 1  # choose a dataset\n",
    "data = {\n",
    "    1: np.loadtxt('datasets/MackeyGlass_t17.txt'),  # MSE = 1.00835041454e-06\n",
    "\n",
    "}[v]\n",
    "print (\"done\")\n",
    "\n",
    "f = pd.read_csv(\"datasets/MackeyGlass_t17.txt\", header=None)\n",
    "min = f.min()\n",
    "max = f.max()\n",
    "\n",
    "# if not necessary do not rebuild\n",
    "data = f.as_matrix(columns=[0])\n",
    "nvalues = data.shape[0]\n",
    "print (\"values: \" + str(nvalues))\n",
    "\n",
    "# normalize the data and the target\n",
    "minmaxnorm(data, min, max)\n",
    "\n",
    "data_train = data[:train_rows]\n",
    "target_train = data[1:train_rows + 1]\n",
    "data_test = data[train_rows - testWashout:train_rows + test_rows]\n",
    "target_test = data[train_rows + 1 - testWashout:train_rows + 1 + test_rows]\n",
    "\n",
    "figure()\n",
    "plot(f[:800], c='g')\n",
    "title('A sample of the Mackey-Glass ${\\\\tau}=17$ data')\n",
    "\n",
    "Nu = Ny = 1\n",
    "NrList = [500, 100, 50]  # , 1000]\n",
    "rhoList = [1.25, 0.8, 0.90, 0.99, 1.50]\n",
    "aList = [0.3, 0.5, 0.7, 1.0]\n",
    "betaList = [1e-8, 1e-6, 1e-4, 0.01]\n",
    "generative = True\n",
    "win = 1\n",
    "res = []\n",
    "\n",
    "param_names = ('mse', 'Nr', 'rho', 'a', 'Lambda', 'conn')\n",
    "best_paramd = dict(zip(param_names, (float(\"inf\"), 500, 1.25, 0.3, 1e-8, 30)))\n",
    "\n",
    "print_all = True\n",
    "use_lsv = False\n",
    "model_selection = True\n",
    "if model_selection:\n",
    "    for Nr in NrList:  # reservoir size\n",
    "        for rho in rhoList:  # expected rho\n",
    "            net = esn.Esn(Nu=Nu, Ny=Ny, Nr=Nr, a=0.3, conn=best_paramd['conn'],\n",
    "                          rho=rho, Lambda=1e-8, win=win, lsv=use_lsv)\n",
    "\n",
    "            for a in aList:  # leaking rate\n",
    "                # a is used only to compute the new state x,\n",
    "                # I do not need to build a new net\n",
    "                net.a = a\n",
    "                X = net.fit_data(data_train, trainWashout)\n",
    "                x_state = net.x  # backup of the state, every test will start from this one\n",
    "                Yt = target_train  # the target of u(t) is u(t+1)\n",
    "\n",
    "                for beta in betaList:  # Lambda is only used for Wout\n",
    "                    net.train_wout(X, Yt[trainWashout:].T, beta)\n",
    "                    Y = net.predict(data_test=data_test, x=x_state, washoutLen=testWashout)\n",
    "                    mse = computeMse(target_test[testWashout:], Y)\n",
    "                    if mse < best_paramd['mse']:\n",
    "                        best_paramd.update(dict(zip(('mse', 'Nr', 'rho', 'a', 'Lambda'), (mse, Nr, rho, a, beta))))\n",
    "                        print best_paramd\n",
    "                    # res += [(mse, Nr, rho, a, Lambda)]  # best_param(mse, nr, rho, a, Lambda)\n",
    "                    print ('MSE = ' + str(mse))\n",
    "\n",
    "# best model retraining\n",
    "print (\"best run: \"),\n",
    "print (\"params \"),\n",
    "print (best_paramd)\n",
    "\n",
    "# best_param(mse, nr, rho, a, Lambda)\n",
    "net = esn.Esn(Nu=Nu, Ny=Ny, Nr=best_paramd['Nr'], a=best_paramd['a'], conn=best_paramd['conn'],\n",
    "              rho=best_paramd['rho'], Lambda=best_paramd['Lambda'], win=win, lsv=use_lsv)\n",
    "\n",
    "print (\"data fitting...\"),\n",
    "t1 = datetime.now()\n",
    "X = net.fit_data(data_train, trainWashout)\n",
    "t2 = datetime.now()\n",
    "print (\"done in sec \"),\n",
    "print (t2 - t1).total_seconds()  # millisec\n",
    "\n",
    "print (\"Wout train... done in sec \"),\n",
    "t1 = datetime.now()\n",
    "net.train_wout(X, target_train[trainWashout:].T, net.Lambda)\n",
    "t2 = datetime.now()\n",
    "print (t2 - t1).total_seconds()  # millisec\n",
    "\n",
    "print (\"prediction... done in sec \"),\n",
    "t1 = datetime.now()\n",
    "Y = net.predict(data_test=data_test, x=net.x, washoutLen=testWashout)\n",
    "t2 = datetime.now()\n",
    "print (t2 - t1).total_seconds()  # millisec\n",
    "\n",
    "print \"computing mse...\",\n",
    "mse = computeMse(target_test[testWashout:], Y)\n",
    "print 'MSE = ' + str(mse)\n",
    "\n",
    "# plot some signals, target and predicted\n",
    "figure()\n",
    "plot(target_test[testWashout:], 'g', label='Target signal')  # green\n",
    "plot(Y, 'b--', label='Free-running predicted signal')  # blue\n",
    "title('Target and generated signals $y(n)$ starting at $n=0$\\n $mse=' + str(mse) + '$')\n",
    "legend(loc='upper right')\n",
    "xlabel(\"time n\")\n",
    "ylabel(\"y(n)\")\n",
    "\n",
    "if print_all:\n",
    "    figure()\n",
    "    plot(X[0:20, 0:200].T)\n",
    "    title('Some reservoir activations $\\mathbf{x}(n)$')\n",
    "\n",
    "    figure()\n",
    "    bar(range(1 + net.Nu + net.Nr), net.W_out.T)\n",
    "    title('Output weights $\\mathbf{W}^{out}$')\n",
    "\n",
    "print \"close all windows to finish\"\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNormParams(data):\n",
    "    \"\"\"\n",
    "      computes the parameters for the normalization of the trajectories\n",
    "    :param data: \n",
    "    :return: a tuple (minlat, maxlat, minlon, maxlon)\n",
    "    \"\"\"\n",
    "    minlat = np.inf\n",
    "    maxlat = -np.inf\n",
    "    minlon = np.inf\n",
    "    maxlon = -np.inf\n",
    "    for idx, row in data.iterrows():\n",
    "        trip_lon = row.POLYLINE[:, 0]\n",
    "        trip_lat = np.array(row['POLYLINE'])[:, 1]\n",
    "        minlat = min(min(trip_lat), minlat)\n",
    "        maxlat = max(max(trip_lat), maxlat)\n",
    "        minlon = min(min(trip_lon), minlon)\n",
    "        maxlon = max(max(trip_lon), maxlon)\n",
    "    return minlat, maxlat, minlon, maxlon\n",
    "\n",
    "\n",
    "def printLenStats(data):\n",
    "    \"\"\"\n",
    "      print the statistics from the field triplen\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"statistics of training trips length: mean\"),\n",
    "    print(data[\"triplen\"].mean()),  # Mean of values\n",
    "    print(\"std\"),\n",
    "    print(data[\"triplen\"].std()),  # Unbiased standard deviation\n",
    "    print (\"var\"),\n",
    "    print (data[\"triplen\"].var()),  # Unbiased variance\n",
    "    print(\"max\"),\n",
    "    print(data[\"triplen\"].max()),\n",
    "    print(\"min\"),\n",
    "    print(data[\"triplen\"].min())\n",
    "\n",
    "\n",
    "def doSubmission(data, subfile='/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/data/submission.csv'):\n",
    "    \"\"\"\n",
    "     Write the csv file with the format 'TRIP_ID', 'LATITUDE', 'LONGITUDE'\n",
    "    :param data: dataframe with at least 'TRIP_ID', 'LATITUDE', 'LONGITUDE'\n",
    "    :param subfile: csv file name\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    data.to_csv(subfile,\n",
    "                columns=['TRIP_ID', 'LATITUDE', 'LONGITUDE'], index=None,\n",
    "                quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "\n",
    "def minmaxnorm2d(v, minv0, maxv0, minv1, maxv1):\n",
    "    v[:, 0] -= minv0\n",
    "    v[:, 0] /= maxv0 - minv0\n",
    "    v[:, 1] -= minv1\n",
    "    v[:, 1] /= maxv1 - minv1\n",
    "    return v\n",
    "\n",
    "\n",
    "def minmaxdenorm2d(v, minv0, maxv0, minv1, maxv1):\n",
    "    \"\"\"\n",
    "     given a 2d vector it denormalize its columns wrt the given parameters\n",
    "    :param v: 2d vector\n",
    "    :param minv0:\n",
    "    :param maxv0:\n",
    "    :param minv1:\n",
    "    :param maxv1:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    v[:, 0] *= maxv0 - minv0\n",
    "    v[:, 0] += minv0\n",
    "    v[:, 1] *= maxv1 - minv1\n",
    "    v[:, 1] += minv1\n",
    "    return v\n",
    "\n",
    "\n",
    "def minmaxdenorm(v, minv, maxv):\n",
    "    \"\"\"\n",
    "     given a 1d vector it denormalize its columns wrt the given parameters\n",
    "    :param v: 1d vector\n",
    "    :param minv:\n",
    "    :param maxv:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    v *= maxv - minv\n",
    "    v += minv\n",
    "    return v\n",
    "\n",
    "\n",
    "def HaversineDistance(lat_sub, lon_sub, lat_real, lon_real):\n",
    "    \"\"\"\n",
    "    :param lat_sub: nparray\n",
    "    :param lon_sub: nparray\n",
    "    :param lat_real: nparray\n",
    "    :param lon_real: nparray\n",
    "    :return: the computed distance in km\n",
    "    \"\"\"\n",
    "    REarth = 6371  # this gives the metrics, now it is set to kilometers\n",
    "    lat = abs(lat_sub - lat_real) * np.pi / 180\n",
    "    lon = abs(lon_sub - lon_real) * np.pi / 180\n",
    "    lat_sub = lat_sub * np.pi / 180\n",
    "    lat_real = lat_real * np.pi / 180\n",
    "    a = np.sin(lat / 2) * np.sin(lat / 2) \\\n",
    "        + np.cos(lat_sub) * np.cos(lat_real) * np.sin(lon / 2) * np.sin(lon / 2)\n",
    "    d = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    d *= REarth\n",
    "    return d\n",
    "\n",
    "\n",
    "def meanHaversineDistance(lat_sub, lon_sub, lat_real, lon_real):\n",
    "    \"\"\"\n",
    "     given the arrays, it computes the mean of the Haversine distances\n",
    "    :param lat_sub: computed/predicted latitudes for each test trip\n",
    "    :param lon_sub: computed/predicted longitudes for each test trip\n",
    "    :param lat_real: real latitudes\n",
    "    :param lon_real: real longitudes\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return np.mean(HaversineDistance(lat_sub, lon_sub, lat_real, lon_real))\n",
    "\n",
    "\n",
    "def computeMse(data_target, Y):\n",
    "    \"\"\"\n",
    "     compute MSE for the first errorLen time steps\n",
    "    :param data_target: matrix with a pattern per row\n",
    "    :param Y: my output, matrix with a pattern per row\n",
    "    :return: the computed mse\n",
    "    \"\"\"\n",
    "    if data_target.shape != Y.shape:\n",
    "        print(\"the shapes does not correspond\"),\n",
    "        print(data_target.shape),\n",
    "        print(Y.shape)\n",
    "        exit(-1)\n",
    "    return np.sum(np.square(data_target - Y) / Y.shape[0])\n",
    "\n",
    "\n",
    "def plot_trips(data, n_trips, name):\n",
    "    \"\"\"\n",
    "      It uses the field \"POLYLINE\" in the data\n",
    "    :param data: \n",
    "    :param n_trips: \n",
    "    :param name: destination file name\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    savedir = \"/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Images/\"\n",
    "    bins = 1000\n",
    "    lat_min, lat_max = 41.04961, 41.24961\n",
    "    lon_min, lon_max = -8.71099, -8.51099\n",
    "    z = np.zeros((bins, bins))\n",
    "    latlon = np.array([(lat, lon)\n",
    "                       for path in data.POLYLINE\n",
    "                       for lon, lat in path if len(path) > 0])\n",
    "    figure()\n",
    "    z += np.histogram2d(*latlon.T, bins=bins,\n",
    "                        range=[[lat_min, lat_max],\n",
    "                               [lon_min, lon_max]])[0]\n",
    "    log_density = np.log(1 + z)\n",
    "    title(str(n_trips) + ' Taxi trips')\n",
    "    imshow(log_density[::-1, :],  # flip vertically\n",
    "           extent=[lat_min, lat_max, lon_min, lon_max])\n",
    "    savefig(savedir + name)\n",
    "    print(\"img file saved in \" + savedir + name)\n",
    "\n",
    "\n",
    "def print_data(data, label, marker):\n",
    "    c = np.random.rand(3, 1)\n",
    "    longs = []\n",
    "    lats = []\n",
    "    for idx, row in data.iterrows():\n",
    "        longs.append(row['POLYLINE'][:, 0][-1])\n",
    "        lats.append(row['POLYLINE'][:, 1][-1])\n",
    "    scatter(longs, lats, c=c, label=label, marker=marker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Esn:\n",
    "    def __init__(self, Nu=1, Ny=1, Nr=100, a=1, conn=100, rho=0.99, Lambda=0, win=1, lsv=True):\n",
    "        \"\"\"\n",
    "         Constructor of the net, prepare and initialize the esn\n",
    "        :param Nu: input units\n",
    "        :param Ny: output units\n",
    "        :param Nr: reservoir size\n",
    "        :param a: leaking rake\n",
    "        :param conn: % of connectivity\n",
    "        :param rho: or lsv to which scale the reservoir\n",
    "        :param Lambda: regularization parameter\n",
    "        :param win: input weights scaling\n",
    "        :param lsv: True - use the largest sing value for normalizing W\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.Nu = Nu  # input dim\n",
    "        self.Ny = Ny  # output dim\n",
    "        self.Nr = Nr  # reservoir dim\n",
    "        self.a = a  # leaking rate\n",
    "        self.connectivity = conn\n",
    "        self.Lambda = Lambda  # regularization coefficient\n",
    "        self.x = np.zeros((self.Nr, 1))  # init the reservoir-net-state\n",
    "\n",
    "        np.random.seed(5)  # fixed\n",
    "        # input connections, plus the bias unit\n",
    "        self.W_in = (np.random.rand(Nr, 1 + Nu) - 0.5) * win  # win is the input scaling\n",
    "        # reservoir connections, make them sparse!\n",
    "        self.W = np.random.rand(Nr, Nr) - 0.5\n",
    "        # -5 halves the values\n",
    "        eps = 0.5 * conn / 100\n",
    "        # leave only the conn % of the connections\n",
    "        self.W[abs(self.W) > eps] = 0\n",
    "        self.W_out = np.zeros((Nr, Nr))\n",
    "\n",
    "        if not lsv:\n",
    "            print('Computing spectral radius...'),\n",
    "            t1 = datetime.now()\n",
    "            rhoW = np.max(np.abs(linalg.eigvals(self.W)))  # esn necessary condition\n",
    "            self.W *= rho / rhoW\n",
    "\n",
    "        else:\n",
    "            print('Computing largest sing value...'),\n",
    "            t1 = datetime.now()\n",
    "            # compute the matrix 2-norm (largest sing. value), esn sufficient condition\n",
    "            lsv = linalg.norm(self.W, 2)\n",
    "            self.W *= rho / lsv\n",
    "\n",
    "        t2 = datetime.now()\n",
    "        print('done in'),\n",
    "        print (t2 - t1).total_seconds(),\n",
    "        print('sec')\n",
    "\n",
    "    def fit_data(self, data, washoutLen=0):\n",
    "        \"\"\"\n",
    "         the reservoir-net-state is updated for each training sample,\n",
    "         warm-up with washoutLen rows\n",
    "        :param data: the sequence: a matrix with a pattern per row\n",
    "        :param washoutLen: transient to discard\n",
    "        :return: the collected activation state\n",
    "        \"\"\"\n",
    "        # allocated memory for the design (collected states) matrix\n",
    "        # X instead of  [1|U|X]\n",
    "        X = np.zeros((1 + self.Nu + self.Nr, data.shape[0] - washoutLen))\n",
    "        # XX = np.zeros((1 + Nu + Nr, 1 + Nu + Nr))\n",
    "        # YX = np.zeros((Ny, 1 + Nu + Nr))\n",
    "        # run the reservoir with the data and collect X, skip washoutLen elements \"wash out\"\n",
    "        self.x = np.zeros(self.Nr)  # start from the 0 state\n",
    "        for t in range(washoutLen):\n",
    "            u = data[t]\n",
    "            u = np.append(1, u)\n",
    "            self.x = (1 - self.a) * self.x \\\n",
    "                     + self.a * np.tanh(np.dot(self.W_in, u) + np.dot(self.W, self.x))\n",
    "\n",
    "        for t in range(washoutLen, data.shape[0]):\n",
    "            u = data[t]\n",
    "            u = np.append(1, u)\n",
    "            self.x = (1 - self.a) * self.x \\\n",
    "                     + self.a * np.tanh(np.dot(self.W_in, u) + np.dot(self.W, self.x))\n",
    "            # the states matrix X stores also the input u, for direct input-output connections\n",
    "            X[:, t - washoutLen] = np.append(u, self.x)\n",
    "            # x1 = np.vstack((1, u, x))\n",
    "            # XX += np.dot(x1, x1.T)  # cumulative update of the design matrix\n",
    "            # YX += np.dot(u, x1.T)  # cumulative update\n",
    "        return X\n",
    "\n",
    "    def train_wout(self, X, Yt, Lambda):\n",
    "        \"\"\"\n",
    "         train the output Wout, given X and the relative Yt\n",
    "        :param X: collected (col-wise) training states, [x(1),x(2),..]\n",
    "        :param Yt: collected (col-wise) target outputs, [y1,y2,..]\n",
    "        :param Lambda: regularization param\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # also input and bias units contribute for the output\n",
    "        # X instead of  [1|U|X]\n",
    "        X_T = X.T\n",
    "        YX = np.dot(Yt, X_T)\n",
    "        self.W_out = np.dot(YX, linalg.inv(np.dot(X, X_T) + Lambda * np.eye(1 + self.Nu + self.Nr)))\n",
    "        # W_out = dot( Yt, linalg.pinv(X) )\n",
    "        # W_out = np.dot(YX, linalg.inv(XX + Lambda * np.eye(1 + Nu + Nr)))  # using the precomputed XX & YX\n",
    "\n",
    "    def predict(self, data_test, x, washoutLen=0, generative_mode=True):\n",
    "        \"\"\"\n",
    "         the test method does not modify the reservoir-net-state\n",
    "         it uses all the data skipping the first washoutLen rows\n",
    "        :param data_test: sequence, matrix with a sample per row, as many cols as sample-attributes\n",
    "        :param x: is the starting state of the reservoir\n",
    "        :param washoutLen: num of patterns just to warm up the state\n",
    "        :param generative_mode: True, the output is used as the next input (self-feeding);\n",
    "                                False, takes the input from the data\n",
    "        :return: a matrix with one predicted output per row one foreach test pattern\n",
    "        \"\"\"\n",
    "        # preallocate the output matrix\n",
    "        Y = np.zeros((data_test.shape[0] - washoutLen, self.Ny))\n",
    "\n",
    "        for t in range(washoutLen):\n",
    "            u = data_test[t]\n",
    "            u = np.append(1, u)\n",
    "            # just \"warm up\" the net state x\n",
    "            x = (1 - self.a) * x + self.a * np.tanh(\n",
    "                np.dot(self.W_in, u) + np.dot(self.W, x))\n",
    "\n",
    "        length = data_test.shape[0] - 1\n",
    "        # start testing with the left sequence\n",
    "        u = data_test[washoutLen]\n",
    "        for t in range(washoutLen, data_test.shape[0]):\n",
    "            u = np.append(1, u)\n",
    "            x = (1 - self.a) * x \\\n",
    "                + self.a * np.tanh(np.dot(self.W_in, u) + np.dot(self.W, x))\n",
    "\n",
    "            y = np.dot(self.W_out, np.append(u, x))\n",
    "            Y[t - washoutLen] = y  # insert the output y row-wise\n",
    "            if generative_mode:\n",
    "                # generative mode, feed the output to the next input:\n",
    "                u = y\n",
    "            else:\n",
    "                # predictive mode, take the next input from the data:\n",
    "                if t < length:\n",
    "                    u = data_test[t + 1]  # the new input is taken from the test set\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ntrips_train, ntrips_test, washout_fraction=0):\n",
    "    \"\"\"\n",
    "      data loading and preprocessing\n",
    "    :param ntrips_train:\n",
    "    :param ntrips_test:\n",
    "    :param washout_fraction:\n",
    "    :return: the tuple data_train, data_test, Tcollected, (minlon, maxlon, minlat, maxlat)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    note: for the charts the (lat, long) coordinates correspond to (y, x) in the cartesian plane\n",
    "    in the polyline they are memorized as (long, lat) gps points\n",
    "    \"\"\"\n",
    "    print(\"loading data...\"),\n",
    "    data_train = pd.read_csv('/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/data/train_df.csv', nrows=ntrips_train,\n",
    "                             usecols=[\"TRIP_ID\", \"POLYLINE\"],\n",
    "                             converters={\n",
    "                                 'POLYLINE': lambda x: np.array(json.loads(x))})  # [[lon lat]...[lon lat]] layout\n",
    "    print(\"done\")\n",
    "\n",
    "    data_train['triplen'] = data_train[\"POLYLINE\"].apply(lambda x: x.shape[0])\n",
    "    data_train = data_train[data_train['triplen'] > 0]\n",
    "\n",
    "    # create the training trips image\n",
    "    plot_trips(data_train, ntrips_train, \"taxi_train_trips.png\")\n",
    "    printLenStats(data_train)\n",
    "\n",
    "    # normalize the trajectories\n",
    "    minlat, maxlat, minlon, maxlon = computeNormParams(data_train)\n",
    "    data_train.POLYLINE.apply(lambda x: minmaxnorm2d(x, minlon, maxlon, minlat, maxlat))\n",
    "\n",
    "    # build the training target set\n",
    "    data_train['target'] = 's'\n",
    "    for idx, row in data_train.iterrows():\n",
    "        l = row[\"triplen\"]\n",
    "        # v is a tuple (targetlon, targetlat)\n",
    "        v = row[\"POLYLINE\"][-1]\n",
    "        # replicate it for the length of each trip, discarding transient% of the trip\n",
    "        v = [(v[0], v[1])] * (l - int(l * washout_fraction))\n",
    "        data_train.at[idx, 'target'] = v\n",
    "    # cumulate the target [t1t1t1,..,tntntntn] and transpose for col-wise collection\n",
    "    Tcollected = np.array([y for x in data_train['target'] for y in x]).T\n",
    "    data_train.drop(['target', 'triplen'], axis=1, inplace=True)\n",
    "\n",
    "    # loading validation test data\n",
    "    print(\"loading test data...\"),\n",
    "    data_test = pd.read_csv('/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/data/train_df.csv',\n",
    "                            nrows=ntrips_test, skiprows=range(1, ntrips_train),\n",
    "                            usecols=[\"TRIP_ID\", 'POLYLINE'],\n",
    "                            converters={'POLYLINE': lambda x: np.array(json.loads(x))})  # [[long lat]...[]]\n",
    "    print(\"done\")\n",
    "\n",
    "    # data_test = data_test.sample(1000)\n",
    "    l = data_test[\"POLYLINE\"].apply(lambda x: x.shape[0])\n",
    "    data_test = data_test[l > 0]\n",
    "\n",
    "    # create the test trips image\n",
    "    plot_trips(data_train, ntrips_train, \"taxi_test_trips.png\")\n",
    "\n",
    "    # normalize the trips points wrt the training data\n",
    "    data_test.POLYLINE.apply(lambda x: minmaxnorm2d(x, minlon, maxlon, minlat, maxlat))\n",
    "\n",
    "    return data_train, data_test, Tcollected, (minlon, maxlon, minlat, maxlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection2(net_param,\n",
    "                     data_train, Tcum, data_test,\n",
    "                     norm_param,\n",
    "                     params_lists, washout_fraction=0):\n",
    "    \"\"\"\n",
    "      do the parameter optimization with a grid search through the hyper param lists,\n",
    "      here we use the mean Haversine distance\n",
    "    :param net_param: dictionary with 'Nu', 'Ny', 'use_lsv','Nr','a','rho','Lambda'.'conn'\n",
    "    :param data_train:\n",
    "    :param Tcum: collected training targets\n",
    "    :param data_test:\n",
    "    :param norm_param: tuple (minlon, maxlon, minlat, maxlat) for the denormalization\n",
    "    :param params_lists: tuple (NrList, rhoList, aList, LambdaList)\n",
    "    :param washout_fraction:\n",
    "    :return: the dataframe with all the parameter results tabulated\n",
    "    \"\"\"\n",
    "    NrList, rhoList, aList, LambdaList, connList = params_lists\n",
    "    Lambda = LambdaList[0]\n",
    "    a = aList[0]\n",
    "    conn = connList[0]\n",
    "    param_df = pd.DataFrame()\n",
    "    # to track the progresses\n",
    "    totcv = len(NrList) * len(rhoList) * len(aList) * len(LambdaList)\n",
    "    actcv = 0\n",
    "    for Nr in NrList:  # reservoir size\n",
    "        for rho in rhoList:  # expected rho/lsv\n",
    "            net = esn.Esn(Nu=net_param['Nu'], Ny=net_param['Ny'], Nr=Nr, a=a, conn=conn,\n",
    "                          rho=rho, Lambda=Lambda, lsv=net_param['use_lsv'])\n",
    "            for a in aList:  # leaking rate\n",
    "                # a is used only when computing the new state x, No need to build a new esn\n",
    "                net.a = a\n",
    "                # Xcoll [x1,...,xn] col-wise\n",
    "                Xcoll = fitEsn(data_train, net, washout_fraction)\n",
    "\n",
    "                for Lambda in LambdaList:  # regularization param\n",
    "                    # Lambda is used only when computing Wout\n",
    "                    net.Lambda = Lambda\n",
    "                    print(\"Wout train...\"),\n",
    "                    t1 = datetime.now()\n",
    "                    net.train_wout(Xcoll, Tcum, net.Lambda)\n",
    "                    t2 = datetime.now()\n",
    "                    print(\"done in sec\"),\n",
    "                    print (t2 - t1).total_seconds()\n",
    "\n",
    "                    # ######### Train TEST #########\n",
    "                    MHDtr = applyAndMhd(net, data_train, norm_param, washout_fraction)\n",
    "                    print(\"train mean Haversine Distance: km \" + str(MHDtr))\n",
    "\n",
    "                    # ######### VALIDATION TEST #########\n",
    "                    MHDts = applyAndMhd(net, data_test, norm_param, washout_fraction)\n",
    "                    print(\"validation mean Haversine Distance: km \" + str(MHDts))\n",
    "\n",
    "                    actcv += 1\n",
    "                    print (\"step\" + str(actcv) + \"/\" + str(totcv) + \"-->\"),\n",
    "                    param_df = param_df.append(pd.DataFrame(\n",
    "                        data=dict(zip(('MHDts', 'MHDtr', 'Nr', 'rho', 'a', 'Lambda', 'conn'),\n",
    "                                      ([MHDts], [MHDtr], [Nr], [rho], [a], [Lambda], [conn])))),\n",
    "                        ignore_index=True)\n",
    "                    print(\"best until now: \" + str(param_df['MHDts'].min()))\n",
    "                    if MHDts < param_df['MHDts'].min():\n",
    "                        print (\"++++++NEW BEST!\")\n",
    "                        print (param_df[param_df['MHDts'].idxmin])\n",
    "                    print (\"saving model selection results\")\n",
    "                    param_df.to_csv('/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/data/new.csv', index=False)\n",
    "                    print(\"^^^^^^^^^^^^^^^^^^^^^\")\n",
    "\n",
    "    return param_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEsn(net_param, data_train, Tcoll, washout_fraction=0):\n",
    "    \"\"\"\n",
    "      prepare and train the ESN\n",
    "    :param net_param: dictionary with 'Nu', 'Ny', 'use_lsv','Nr','a','rho','Lambda'.'conn'\n",
    "    :param data_train:\n",
    "    :param Tcoll: col-wise collected train target values\n",
    "    :return: the trained ESN\n",
    "    \"\"\"\n",
    "    net = Esn(Nu=net_param['Nu'], Ny=net_param['Ny'], Nr=net_param['Nr'],\n",
    "                  a=net_param['a'], conn=net_param['conn'],\n",
    "                  rho=net_param['rho'], Lambda=net_param['Lambda'], lsv=net_param['use_lsv'])  # [x1,...,xn]\n",
    "\n",
    "    net.a = net_param['a']\n",
    "    Xcoll = fitEsn(data_train, net, washout_fraction)\n",
    "\n",
    "    print(\"Wout train...\"),\n",
    "    t1 = datetime.now()\n",
    "    net.train_wout(Xcoll, Tcoll, net.Lambda)\n",
    "    t2 = datetime.now()\n",
    "    print(\"done in sec\"),\n",
    "    print (t2 - t1).total_seconds()\n",
    "    return net\n",
    "\n",
    "\n",
    "def fitEsn(data_train, net, washout_fraction):\n",
    "    \"\"\"\n",
    "      updates the net states with the training data, and collect its activations states.\n",
    "    :param data_train:\n",
    "    :param net:\n",
    "    :param washout_fraction:\n",
    "    :return: the collected activation states\n",
    "    \"\"\"\n",
    "    print(\"data fitting\"),\n",
    "    t1 = datetime.now()\n",
    "    Xcoll = np.zeros((1 + net.Nu + net.Nr, 0))\n",
    "    # ##########  TRAIN  ################\n",
    "    # iterate over the taxi trips, the POLYLINE field contains the gps trajectory\n",
    "    # accumulate the activations states\n",
    "    zerovec = np.zeros(net.Nr)\n",
    "    count = 500  # print . every 500 trajectory\n",
    "    for idx, row in data_train.iterrows():\n",
    "        # reset the state\n",
    "        net.x = zerovec\n",
    "        X = net.fit_data(row.POLYLINE,\n",
    "                         washoutLen=int(row.POLYLINE.shape[0] * washout_fraction))\n",
    "        Xcoll = np.append(Xcoll, X, axis=1)\n",
    "\n",
    "        # print a . every 500 trip, just to know where I am\n",
    "        count -= 1\n",
    "        if count == 0:\n",
    "            print(\".\"),\n",
    "            count = 500\n",
    "    t2 = datetime.now()\n",
    "    print (\"done in sec \"),\n",
    "    print (t2 - t1).total_seconds()\n",
    "    return Xcoll\n",
    "\n",
    "\n",
    "def applyEsn(net, data_test, washout_fraction=0):\n",
    "    \"\"\"\n",
    "        add the columns LONGITUDE and LATITUDE into data_valid\n",
    "        notice: this column maintain the eventual normalization of the data\n",
    "    :param net: the ESN to use, already trained\n",
    "    :param data_test:\n",
    "    :param washout_fraction:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ############  TEST  ###################\n",
    "    # iterate over the taxi trips, the POLYLINE field contains the gps trajectory\n",
    "    # accumulate the predicted output and the relative target\n",
    "    # add the columns LONGITUDE and LATITUDE in the test data set\n",
    "    print (\"prediction...\"),\n",
    "    t1 = datetime.now()\n",
    "    for idx, row in data_test.iterrows():\n",
    "        net.x = np.zeros(net.Nr)  # set x(0) = 0\n",
    "        # take only the last prediction, intermediate predictions just to debug/print\n",
    "        # I can even use a washout of trip.len-1 and just predict the last\n",
    "        Y = net.predict(row.POLYLINE, x=net.x, generative_mode=False,\n",
    "                        washoutLen=int(row.POLYLINE.shape[0] * washout_fraction))\n",
    "        data_test.iat(idx, 'LONGITUDE', Y[-1][0])\n",
    "        data_test.iat(idx, 'LATITUDE', Y[-1][1])\n",
    "    print (\"done in sec\"),\n",
    "    print (datetime.now() - t1).total_seconds()\n",
    "\n",
    "\n",
    "def applyAndMhd(net, data, norm_param, washout_fraction=0):\n",
    "    \"\"\"\n",
    "      the target is computed from the data\n",
    "    :param net: to be applied\n",
    "    :param data: data for the test\n",
    "    :param norm_param: normalization tuple (minlon, maxlon, minlat, maxlat)\n",
    "    :param washout_fraction: fraction of the trip len to be used as washout steps\n",
    "    :return: MHD\n",
    "    \"\"\"\n",
    "    minlon, maxlon, minlat, maxlat = norm_param\n",
    "\n",
    "    applyEsn(net, data, washout_fraction)\n",
    "\n",
    "    # denormalize the predictions\n",
    "    minmaxdenorm(data[\"LATITUDE\"], minlat, maxlat)\n",
    "    minmaxdenorm(data[\"LONGITUDE\"], minlon, maxlon)\n",
    "\n",
    "    # collect the targets and denormalize them\n",
    "    target = np.zeros((0, net.Ny))\n",
    "    for idx, row in data.iterrows():\n",
    "        target = np.vstack((target, row.POLYLINE[-1]))\n",
    "    minmaxdenorm2d(target, minlon, maxlon, minlat, maxlat)\n",
    "\n",
    "    return meanHaversineDistance(\n",
    "        data[\"LATITUDE\"], data[\"LONGITUDE\"],\n",
    "        target[:, 1], target[:, 0])\n",
    "\n",
    "\n",
    "def applyAndSubmit(net, norm_param, washout_fraction=0):\n",
    "    minlon, maxlon, minlat, maxlat = norm_param\n",
    "    # load the competition test data\n",
    "    print (\"loading competition test data...\"),\n",
    "    subdata = pd.read_csv('/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/data/test_df.csv',\n",
    "                          usecols=[\"TRIP_ID\", 'POLYLINE'],\n",
    "                          converters={'POLYLINE': lambda x: np.array(json.loads(x))})\n",
    "    print (\"done\")\n",
    "    subdata.POLYLINE.apply(lambda x: minmaxnorm2d(x, minlon, maxlon, minlat, maxlat))\n",
    "\n",
    "    applyEsn(net, subdata, washout_fraction)\n",
    "\n",
    "    # denormalize the predictions\n",
    "    minmaxdenorm(subdata[\"LATITUDE\"], minlat, maxlat)\n",
    "    minmaxdenorm(subdata[\"LONGITUDE\"], minlon, maxlon)\n",
    "\n",
    "    doSubmission(subdata, '/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/data/submission.csv')\n",
    "    print(\"Generation done \" + 'datasets/submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "done\n",
      "img file saved in /Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Images/taxi_train_trips.png\n",
      "statistics of training trips length: mean\n",
      "39.76\n",
      "std\n",
      "26.486222833767748\n",
      "var\n",
      "701.5200000000001\n",
      "max\n",
      "151\n",
      "min\n",
      "1\n",
      "loading test data...\n",
      "done\n",
      "img file saved in /Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Images/taxi_test_trips.png\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'esn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model_selection \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mif\u001b[39;00m model_selection:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     hyp_param_df \u001b[39m=\u001b[39m model_selection2(net_param, data_train, Tcollected,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                                     data_valid, norm_param, hyper_lists,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m                                     washout_fraction\u001b[39m=\u001b[39;49mwashout_fraction)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mended with:\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     winning \u001b[39m=\u001b[39m hyp_param_df\u001b[39m.\u001b[39miloc[hyp_param_df[\u001b[39m\"\u001b[39m\u001b[39mMHDts\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39midxmin()]\n",
      "\u001b[1;32m/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb Cell 7\u001b[0m in \u001b[0;36mmodel_selection2\u001b[0;34m(net_param, data_train, Tcum, data_test, norm_param, params_lists, washout_fraction)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m Nr \u001b[39min\u001b[39;00m NrList:  \u001b[39m# reservoir size\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mfor\u001b[39;00m rho \u001b[39min\u001b[39;00m rhoList:  \u001b[39m# expected rho/lsv\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         net \u001b[39m=\u001b[39m esn\u001b[39m.\u001b[39mEsn(Nu\u001b[39m=\u001b[39mnet_param[\u001b[39m'\u001b[39m\u001b[39mNu\u001b[39m\u001b[39m'\u001b[39m], Ny\u001b[39m=\u001b[39mnet_param[\u001b[39m'\u001b[39m\u001b[39mNy\u001b[39m\u001b[39m'\u001b[39m], Nr\u001b[39m=\u001b[39mNr, a\u001b[39m=\u001b[39ma, conn\u001b[39m=\u001b[39mconn,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                       rho\u001b[39m=\u001b[39mrho, Lambda\u001b[39m=\u001b[39mLambda, lsv\u001b[39m=\u001b[39mnet_param[\u001b[39m'\u001b[39m\u001b[39muse_lsv\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m aList:  \u001b[39m# leaking rate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m             \u001b[39m# a is used only when computing the new state x, No need to build a new esn\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/Esn.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m             net\u001b[39m.\u001b[39ma \u001b[39m=\u001b[39m a\n",
      "\u001b[0;31mNameError\u001b[0m: name 'esn' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ###############  TRAINING PARAMETERS  ############\n",
    "ntrips_train = 200  # num of trips to be read from the file each time\n",
    "ntrips_test = 300  # num of trips to be read from the file each time\n",
    "washout_fraction = 0.2\n",
    "save_results = True\n",
    "savedir = \"/Users/rupesh/Desktop/COD/Duoro_Hawk_Flying_Taxis/\"\n",
    "paramfile = savedir + \"hyp_param_df.csv\"\n",
    "\n",
    "# ###############  DATA LOADING AND PREPROCESSING  ##############\n",
    "data_train, data_valid, Tcollected, norm_param \\\n",
    "    = load_data(ntrips_train, ntrips_test, washout_fraction)\n",
    "\n",
    "# ###############  TRAINING  ###################\n",
    "NrList = [80, 120, 250]  # , 500, 100, 50]  # , 1000]\n",
    "rhoList = [0.4, 0.6, 0.8, 0.9, 1]  # , 0.90, 0.99, 1.25, 1.50]\n",
    "aList = [0.4, 0.8, 1]\n",
    "LambdaList = [1e-4, 1e-3, 1e-2, 0.1]  # , 1e-7, 1e-6, 1e-4]\n",
    "connList = [30]\n",
    "hyper_lists = (NrList, rhoList, aList, LambdaList, connList)\n",
    "\n",
    "Nu = Ny = 2\n",
    "net_param = {'Nu': Nu, 'Ny': Ny, 'use_lsv': True,\n",
    "             'Nr': 250, 'a': 1, 'rho': 0.4, 'Lambda': 0.01,\n",
    "             'conn': 30}\n",
    "\n",
    "# do the parameters grid search\n",
    "# and update the net params with the winning ones\n",
    "model_selection = True\n",
    "if model_selection:\n",
    "    hyp_param_df = model_selection2(net_param, data_train, Tcollected,\n",
    "                                    data_valid, norm_param, hyper_lists,\n",
    "                                    washout_fraction=washout_fraction)\n",
    "    print(\"ended with:\"),\n",
    "    winning = hyp_param_df.iloc[hyp_param_df[\"MHDts\"].idxmin()]\n",
    "    print(winning)\n",
    "\n",
    "    if save_results:\n",
    "        print(\"saving model selection results\")\n",
    "        hyp_param_df.to_csv(paramfile, index=False)\n",
    "    print (\"run the best model\")\n",
    "    net_param['Nr'] = winning['Nr']\n",
    "    net_param['rho'] = winning['rho']\n",
    "    net_param['Lambda'] = winning['Lambda']\n",
    "    net_param['a'] = winning['a']\n",
    "\n",
    "# ###############  WINNER TRAIN  ###########\n",
    "# load more data for the test\n",
    "net = trainEsn(net_param, data_train, Tcollected, washout_fraction)\n",
    "\n",
    "# ###############  OFFICIAL SUBMISSION GENERATION #################\n",
    "# applyAndSubmit(net, norm_param, washout_fraction)\n",
    "# exit()\n",
    "\n",
    "# ###############  Train TEST #########\n",
    "MHD = applyAndMhd(net, data_train, norm_param, washout_fraction)\n",
    "print (\"mean Haversine Distance: km \" + str(MHD))\n",
    "\n",
    "# ###############  VALIDATION TEST #########\n",
    "MHD = applyAndMhd(net, data_valid, norm_param, washout_fraction)\n",
    "print (\"mean Haversine Distance: km \" + str(MHD))\n",
    "\n",
    "# save the bar plot of Wout\n",
    "if save_results:\n",
    "    figure()\n",
    "    bar(range(2 * int(1 + Nu + net.Nr)), net.W_out.T.flatten())\n",
    "    title('Output weights $\\mathbf{W}^{out}$')\n",
    "    savefig(savedir + 'Wout.png')\n",
    "\n",
    "    # figure()\n",
    "    # plot(X[0:20, 0:200].T)\n",
    "    # title('Some reservoir activations $\\mathbf{x}(n)$')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Dec  7 2022, 10:15:13) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
